{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd, adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization\n",
    "# tf.enable_eager_execution() # Allows to get numpy our of tensor, but breaks the gradients\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject on Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "In the function ```act```, the agent chooses which action to perform for the next step.\n",
    "\n",
    "In test mode, it will simply call learned_act and select the best action accordnig to what the agent has learned so far.\n",
    "\n",
    "In train mode, the action has $\\epsilon$ chances to take a random action and $1-\\epsilon$ chances to choose the best action according to what it has learned so far. Allowing for random exploration is essential to provent the agent from staying stuck in local minimas in the policy space, and somtimes try actions that are not optimal w.r.t the current learned policy. The basic idea is to introduce exploration not to imbalance it w.r.t exploitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(you can use Markdown and Latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the rat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=100 # set small when debugging\n",
    "epochs_test=20 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```position``` array indicates the position of the agent, and the available directions for movement: since we do not want the agent to leave the grid, we set to -1 its limits, so that when the agnet receives the cropped cells (before choosing an action), it knows what directions are available to him.\n",
    "\n",
    "The ```board``` array indicates where the rewards and malus are located: the cells have a positive value if they contain a bonus and a negative value if they contain a malus. Both bonus and malus are randomly distributed accross the grid. Similarily to what is done with the ```position``` array, the grid created is artifucially larger than what it should be, to deal with edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        # The adjent acts randomly\n",
    "        a = np.random.randint(0, self.n_action, size=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        while not game_over:\n",
    "            action = agent.act(state)\n",
    "            previous_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "            \n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose - reward\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 3.0/1.0. Average score (2.0)\n",
      "Win/lose count 1.0/4.0. Average score (-0.5)\n",
      "Win/lose count 1.5/3.0. Average score (-0.8333333333333334)\n",
      "Win/lose count 3.0/3.0. Average score (-0.625)\n",
      "Win/lose count 1.0/4.0. Average score (-1.1)\n",
      "Win/lose count 2.0/4.0. Average score (-1.25)\n",
      "Win/lose count 0.5/2.0. Average score (-1.2857142857142858)\n",
      "Win/lose count 2.5/4.0. Average score (-1.3125)\n",
      "Win/lose count 1.0/5.0. Average score (-1.6111111111111112)\n",
      "Win/lose count 2.0/4.0. Average score (-1.65)\n",
      "Win/lose count 2.0/2.0. Average score (-1.5)\n",
      "Win/lose count 1.5/4.0. Average score (-1.5833333333333333)\n",
      "Win/lose count 3.0/7.0. Average score (-1.7692307692307692)\n",
      "Win/lose count 1.5/2.0. Average score (-1.6785714285714286)\n",
      "Win/lose count 4.5/0. Average score (-1.2666666666666666)\n",
      "Win/lose count 3.0/3.0. Average score (-1.1875)\n",
      "Win/lose count 1.5/2.0. Average score (-1.1470588235294117)\n",
      "Win/lose count 2.5/7.0. Average score (-1.3333333333333333)\n",
      "Win/lose count 2.5/0. Average score (-1.131578947368421)\n",
      "Win/lose count 3.5/3.0. Average score (-1.05)\n",
      "Final score: -1.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAE9BtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE0OCByMjY0MyA1YzY1NzA0IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNSAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9OCBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALtZYiEADv//vb8/AptUwndP/9P+VxN2UIE1zAALTEAIgTYlI7FKYvwKUU8/ApmttTF/97HUmEYlMR4bbT+sv1XgPaBS87dzEO/LY7tDf8qsAQok6ne/VtEV14BTp/6L/gGdkjgcCIWXNy5PjbzRCRZfijaz8/k2Coe41H6VWJcA0QkVrb0TyGWGGcK3tZjJp+cA6EKVhz7kVJ2lJU7TPvcmj48EvgYndxIerdVRoWIx8036lBuBudS0eQaHrNyaaFY79SYYthiICYIvdsf/aIytDmjHacKFwmmAsGtw8V6tv38pp1ExNs3K/E/0iA1SxCywdiO3JGj3t4wx1WLI2IijDDedzKQqOLoHqCdBk/FTSLsk2IvbEWkiMGhMHZOvpYxqe7+Gk/VW6gMMzOOdcssgxiCU8Siy+ib5VmTQbeHMwMzSO3KzdpE12bwbxsUSLrsHYGg88w1Rty/r6xymtTMhyOlYgaOqfUVz2IXvx72kcKol87eZ+PBeGZ+TTB8VjUXyiJ+PmdkngCDAfR42Urvg3jx/2eW+9sDj0JWSKXCstJSEb967xG1NmWGFPl957XY0RtfyKB0ANideJf1k7OAzpi+cAEHMN000zeABG7EfYud23VU3De0wDPio+B2fxEE/FauP0Pr2yzHkwaGZpurSlVlv+sbUTz+YVvVCpxdt3FccM4+2ujxA7LCxfBdEeJqmFLHS+YcKXwi0uSUzaat7o9IL2tdTMtkhMk/R+giujU9W8xL1Lboon8jPBdBsBFUNOdaJ9YvV5IF0Gwf5K+vfzY15AMz6VbqCS8qzhi/1HoEtsuphwSQ6ITMQmHuP9LCG4V85uclMSfxeSnlMj1fe2FhZEm3IoZFT0VzYmZp+hZrejr7w3/5vggssIYNIVAnfqOLyRA9/MR8E5XZdHOsmx08HnNIcXxACRwOGgrfsMYnX/QghzfQcggcwjL21SfrrsfwLjiKU9xKRodeb8vRMyTYDvDsPMxad74AAUcAAAANQZokbEO//qmWAACVgAAAAApBnkJ4hf8AALKBAAAACgGeYXRCvwAA7oAAAAAKAZ5jakK/AADugQAAABNBmmhJqEFomUwId//+qZYAAJWBAAAADEGehkURLC//AACygQAAAAoBnqV0Qr8AAO6BAAAACgGep2pCvwAA7oAAAAATQZqsSahBbJlMCHf//qmWAACVgAAAAAxBnspFFSwv/wAAsoEAAAAKAZ7pdEK/AADugAAAAAoBnutqQr8AAO6AAAAAE0Ga8EmoQWyZTAh3//6plgAAlYEAAAAMQZ8ORRUsL/8AALKBAAAACgGfLXRCvwAA7oEAAAAKAZ8vakK/AADugAAAABNBmzRJqEFsmUwId//+qZYAAJWAAAAADEGfUkUVLC//AACygQAAAAoBn3F0Qr8AAO6AAAAACgGfc2pCvwAA7oAAAAAbQZt4SahBbJlMCHf//qmWANo5Bmfypep/k1xxAAAAD0GflkUVLC//AOz+yvnhYAAAAA0Bn7V0Qr8BSMyiZPqhAAAACgGft2pCvwAA7oEAAAATQZu8SahBbJlMCHf//qmWAACVgAAAAAxBn9pFFSwv/wAAsoEAAAAKAZ/5dEK/AADugAAAAAoBn/tqQr8AAO6BAAAAE0Gb4EmoQWyZTAh3//6plgAAlYEAAAAMQZ4eRRUsL/8AALKAAAAACgGePXRCvwAA7oAAAAAKAZ4/akK/AADugQAAABdBmiRJqEFsmUwId//+qZYCkJZXIXA/wAAAAA5BnkJFFSwv/wF6/bM3oQAAABABnmF0Qr8B+iAOhQxJjyZgAAAACgGeY2pCvwAA7oEAAAATQZpoSahBbJlMCHf//qmWAACVgQAAAAxBnoZFFSwv/wAAsoEAAAAKAZ6ldEK/AADugQAAAAoBnqdqQr8AAO6AAAAAE0GarEmoQWyZTAh3//6plgAAlYAAAAAMQZ7KRRUsL/8AALKBAAAACgGe6XRCvwAA7oAAAAAKAZ7rakK/AADugAAAABNBmvBJqEFsmUwId//+qZYAAJWBAAAADEGfDkUVLC//AACygQAAAAoBny10Qr8AAO6BAAAACgGfL2pCvwAA7oAAAAAaQZs0SahBbJlMCHf//qmWAOPYb8pox+lAHtAAAAAPQZ9SRRUsL/8A8n2h1qihAAAADQGfcXRCvwFRyytLMWAAAAAKAZ9zakK/AADugAAAABNBm3hJqEFsmUwId//+qZYAAJWBAAAADEGflkUVLC//AACygAAAAAoBn7V0Qr8AAO6BAAAACgGft2pCvwAA7oEAAAATQZu8SahBbJlMCHf//qmWAACVgAAAAAxBn9pFFSwv/wAAsoEAAAAKAZ/5dEK/AADugAAAAAoBn/tqQr8AAO6BAAAAE0Gb4EmoQWyZTAh3//6plgAAlYEAAAAMQZ4eRRUsL/8AALKAAAAACgGePXRCvwAA7oAAAAAKAZ4/akK/AADugQAAABNBmiRJqEFsmUwId//+qZYAAJWAAAAADEGeQkUVLC//AACygQAAAAoBnmF0Qr8AAO6AAAAACgGeY2pCvwAA7oEAAAAcQZpoSahBbJlMCHf//qmWAtPIMz4ul0Dh/Yc6YQAAAA9BnoZFFSwv/wGH72/X6VkAAAAKAZ6ldEK/AADugQAAAA0BnqdqQr8CCttVw0rAAAAAE0GarEmoQWyZTAh3//6plgAAlYAAAAAMQZ7KRRUsL/8AALKBAAAACgGe6XRCvwAA7oAAAAAKAZ7rakK/AADugAAAABNBmvBJqEFsmUwId//+qZYAAJWBAAAADEGfDkUVLC//AACygQAAAAoBny10Qr8AAO6BAAAACgGfL2pCvwAA7oAAAAATQZs0SahBbJlMCHf//qmWAACVgAAAAAxBn1JFFSwv/wAAsoEAAAAKAZ9xdEK/AADugAAAAAoBn3NqQr8AAO6AAAAAGkGbeEmoQWyZTAh3//6plgLTyDM9qJx+nkPBAAAAD0GflkUVLC//AYfvb9fpWAAAAAoBn7V0Qr8AAO6BAAAADQGft2pCvwIK21XDSsEAAAATQZu8SahBbJlMCHf//qmWAACVgAAAAAxBn9pFFSwv/wAAsoEAAAAKAZ/5dEK/AADugAAAAAoBn/tqQr8AAO6BAAAAGkGb4EmoQWyZTAh3//6plgDmdpeFqCfvYltBAAAAD0GeHkUVLC//APJ9odaooAAAAA0Bnj10Qr8BUUz/5ZiwAAAACgGeP2pCvwAA7oEAAAATQZokSahBbJlMCHf//qmWAACVgAAAAAxBnkJFFSwv/wAAsoEAAAAKAZ5hdEK/AADugAAAAAoBnmNqQr8AAO6BAAAAE0GaaEmoQWyZTAh3//6plgAAlYEAAAAMQZ6GRRUsL/8AALKBAAAACgGepXRCvwAA7oEAAAAKAZ6nakK/AADugAAAABpBmqxJqEFsmUwId//+qZYA450/KaMfpQB7QAAAAA9BnspFFSwv/wDyfaHWqKEAAAANAZ7pdEK/AVFM/+WYsAAAAAoBnutqQr8AAO6AAAAAGkGa8EmoQWyZTAh3//6plgDmdpfzCkKYNrehAAAAD0GfDkUVLC//APJ+yvngYQAAAA0Bny10Qr8BUU5S3HyxAAAACgGfL2pCvwAA7oAAAAATQZs0SahBbJlMCHf//qmWAACVgAAAAAxBn1JFFSwv/wAAsoEAAAAKAZ9xdEK/AADugAAAAAoBn3NqQr8AAO6AAAAAGkGbeEmoQWyZTAh3//6plgCIFHOtD1ffIUnBAAAAD0GflkUVLC//AKPPr2rXjAAAAAoBn7V0Qr8AAO6BAAAADQGft2pCvwDckaBrScEAAAATQZu8SahBbJlMCHf//qmWAACVgAAAAAxBn9pFFSwv/wAAsoEAAAAKAZ/5dEK/AADugAAAAAoBn/tqQr8AAO6BAAAAE0Gb4EmoQWyZTAh3//6plgAAlYEAAAAMQZ4eRRUsL/8AALKAAAAACgGePXRCvwAA7oAAAAAKAZ4/akK/AADugQAAACdBmiRJqEFsmUwId//+qZYA+/Pd5llapqvApRIF4FM1ywy3PNw2ccAAAAASQZ5CRRUsL/8A/s+53N17JEvBAAAADQGeYXRCvwDiRUBNLKAAAAANAZ5jakK/AWOx5uE9qQAAABNBmmhJqEFsmUwId//+qZYAAJWBAAAADEGehkUVLC//AACygQAAAAoBnqV0Qr8AAO6BAAAACgGep2pCvwAA7oAAAAAaQZqsSahBbJlMCHf//qmWAQVRzpNEN4LYSkgAAAAPQZ7KRRUsL/8BBp611qVhAAAADQGe6XRCvwFsTP/lltAAAAAKAZ7rakK/AADugAAAABpBmvBJqEFsmUwId//+qZYBE9nOtD1faqSZgQAAAA9Bnw5FFSwv/wEOnrXWpGEAAAANAZ8tdEK/AXVM/+WWUQAAAAoBny9qQr8AAO6AAAAAE0GbNEmoQWyZTAh3//6plgAAlYAAAAAMQZ9SRRUsL/8AALKBAAAACgGfcXRCvwAA7oAAAAAKAZ9zakK/AADugAAAABNBm3hJqEFsmUwId//+qZYAAJWBAAAADEGflkUVLC//AACygAAAAAoBn7V0Qr8AAO6BAAAACgGft2pCvwAA7oEAAAAaQZu8SahBbJlMCHf//qmWASOllZnkJSAADUgAAAAPQZ/aRRUsL/8BFp611qNhAAAADQGf+XRCvwF/kTCaNSAAAAAKAZ/7akK/AADugQAAABNBm+BJqEFsmUwId//+qZYAAJWBAAAADEGeHkUVLC//AACygAAAAAoBnj10Qr8AAO6AAAAACgGeP2pCvwAA7oEAAAATQZokSahBbJlMCHf//qmWAACVgAAAAAxBnkJFFSwv/wAAsoEAAAAKAZ5hdEK/AADugAAAAAoBnmNqQr8AAO6BAAAAE0GaaEmoQWyZTAh3//6plgAAlYEAAAAMQZ6GRRUsL/8AALKBAAAACgGepXRCvwAA7oEAAAAKAZ6nakK/AADugAAAABpBmqxJqEFsmUwId//+qZYBJ++rKrM2tkSVgAAAAA9BnspFFSwv/wEWnrXWo2EAAAANAZ7pdEK/AX7/l+WVsAAAAAoBnutqQr8AAO6AAAAAGkGa8EmoQWyZTAh3//6plgR6kGZ7p5j6sGfBAAAAD0GfDkUVLC//AcMiZcQ4IQAAAA0Bny10Qr8CXcTjJhbRAAAACgGfL2pCvwAA7oAAAAATQZs0SahBbJlMCHf//qmWAACVgAAAAAxBn1JFFSwv/wAAsoEAAAAKAZ9xdEK/AADugAAAAAoBn3NqQr8AAO6AAAAAE0GbeEmoQWyZTAh3//6plgAAlYEAAAAMQZ+WRRUsL/8AALKAAAAACgGftXRCvwAA7oEAAAAKAZ+3akK/AADugQAAABpBm7xJqEFsmUwId//+qZYEn4UfQAYdHtJ1wAAAAA9Bn9pFFSwv/wHDImXEOCEAAAANAZ/5dEK/Al3E4yYW0AAAAAoBn/tqQr8AAO6BAAAAEkGb4EmoQWyZTAhv//6nhAABJwAAABFBnh5FFSwv/wEWj5uqx01GwAAAAA0Bnj10Qr8Bfv+X5ZWwAAAADQGeP2pCvwF/I0DWVsEAAAAZQZokSahBbJlMCG///qeEAimm3Ehgt6REXAAAAA9BnkJFFSwv/wEOn+753VEAAAANAZ5hdEK/AXVOUtx6EAAAAAoBnmNqQr8AAO6BAAAAEkGaaEmoQWyZTAhf//6MsAAEjQAAAAxBnoZFFSwv/wAAsoEAAAAKAZ6ldEK/AADugQAAAAoBnqdqQr8AAO6AAAAAGkGaqUuoQhBbJEYIKAfyAf2HgCFf/jhAABFwAAAMiW1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAB+QAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAuzdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAB+QAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEQAAABEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAfkAAABAAAAQAAAAALK21kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAZQAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAACtZtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAqWc3RibAAAAJZzdHNkAAAAAAAAAAEAAACGYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEQARAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAADBhdmNDAfQADf/hABdn9AANkZsoIhHQgAAAAwCAAAAZB4oUywEABmjr48RIRAAAABhzdHRzAAAAAAAAAAEAAADKAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAGYGN0dHMAAAAAAAAAygAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAFogAAABEAAAAOAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAHwAAABMAAAARAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAGwAAABIAAAAUAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAAB4AAAATAAAAEQAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAIAAAABMAAAAOAAAAEQAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAAB4AAAATAAAADgAAABEAAAAXAAAAEAAAAA4AAAAOAAAAHgAAABMAAAARAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAHgAAABMAAAARAAAADgAAAB4AAAATAAAAEQAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAHgAAABMAAAAOAAAAEQAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAKwAAABYAAAARAAAAEQAAABcAAAAQAAAADgAAAA4AAAAeAAAAEwAAABEAAAAOAAAAHgAAABMAAAARAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAHgAAABMAAAARAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAAB4AAAATAAAAEQAAAA4AAAAeAAAAEwAAABEAAAAOAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAeAAAAEwAAABEAAAAOAAAAFgAAABUAAAARAAAAEQAAAB0AAAATAAAAEQAAAA4AAAAWAAAAEAAAAA4AAAAOAAAAHgAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ni40MC4xMDE=\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- Let us prove the first point:\n",
    "\\begin{align*}\n",
    "Q^\\pi(s,a) &= \\mathbb{E}_{p^\\pi}[\\sum_{t=0}^\\infty\\gamma^tr(s_t, a_t)|s_0=s, a_0=a]\\\\\n",
    "&= \\mathbb{E}_{p^\\pi}[r(s_0,a_0) + \\sum_{t=1}^\\infty\\gamma^tr(s_t, a_t)|s_0=s, a_0=a]\\\\\n",
    "&= r(s,a) + \\mathbb{E}_{p^\\pi}[\\sum_{t=1}^\\infty\\gamma^tr(s_t, a_t)|s_0=s, a_0=a]\\\\\n",
    "&= r(s,a) + \\mathbb{E}_{p^\\pi}[\\mathbb{E}_{p^\\pi}[\\sum_{t=1}^\\infty\\gamma^tr(s_t, a_t)|s_1,a_1]|s_0=s, a_0=a]\\\\\n",
    "&= r(s,a) + \\sum_{s',a'}p_\\pi(s',a'|s_0,a_0)\\mathbb{E}_{p^\\pi}[\\sum_{t=1}^\\infty\\gamma^tr(s_t, a_t)|s_1=s',a_1=a']\\\\\n",
    "&= r(s,a) + \\gamma\\sum_{s',a'}p_\\pi(s',a'|s_0,a_0)\\mathbb{E}_{p^\\pi}[\\sum_{t=1}^\\infty\\gamma^{t-1}tr(s_t, a_t)|s_1=s',a_1=a']\\\\\n",
    "&= r(s,a) + \\gamma\\sum_{s',a'}p_\\pi(s',a'|s_0,a_0)Q^\\pi(s',a')\\\\\n",
    "&= \\mathbb{E}_{p^\\pi}[r(s,a) + \\gamma Q^{\\pi}(s',a')]\n",
    "\\end{align*}\n",
    "\n",
    "- Then for the second point, applying the previous equality to $\\pi^*$ the optimal policy:\n",
    "\\begin{align*}\n",
    "Q^*(s,a) &= \\mathbb{E}_{s', a'\\sim p^{\\pi^*}}[r(s,a)+\\gamma Q^*(s',a')]\\\\\n",
    "&= \\mathbb{E}_{s'}[\\mathbb{E}_{a'\\sim\\pi^*}[r(s,a) + \\gamma Q^*(s', a')]]\\\\\n",
    "\\end{align*}\n",
    "By contradiction, suppose that there exist a state $s'$ and an action $a'$ such that $\\pi(a',s')>0$ where $Q^*(s', a')<\\max_a Q^*(s', a)$. Then take $\\hat{\\pi}$ a such that $\\hat{\\pi}(s,.)=\\pi^*(s,.)$ for $s\\neq s'$ and $\\hat{\\pi}(s',a)=\\mathbb{1}_{a=argmax_a Q^*(s', a)}$. We then have:\n",
    "\\begin{align*}\n",
    "\\mathbb{E}_{a'\\sim\\pi^*}[r(s,a) + \\gamma Q^*(s', a')]&<\\mathbb{E}_{a'\\sim\\hat{\\pi}}[r(s,a) + \\gamma Q^*(s', a')]\\\\\n",
    "\\mathbb{E}_{s'}[\\mathbb{E}_{a'\\sim\\pi^*}[r(s,a) + \\gamma Q^*(s', a')]]&<\\mathbb{E}_{s'}[\\mathbb{E}_{a'\\sim\\hat{\\pi}}[r(s,a) + \\gamma Q^*(s', a')]]\n",
    "\\end{align*}\n",
    "And thus $Q^*(s,a)<Q^{\\hat\\pi}$, which breaks the definition of $Q^*$.\n",
    "\n",
    "We thus have that $\\forall s, \\pi^*(s,a)=\\mathbb{1}_{a\\in argmax_{a'}}Q^*(s,a')$ and thus:\n",
    "\\begin{align*}\n",
    "Q^*(s,a) = \\mathbb{E}_{s'}[r(s,a) + \\gamma\\max_{a'}Q^*(s',a')]\n",
    "\\end{align*}\n",
    "\n",
    "- The intuition for the loss is then the following:\n",
    "\n",
    "We know that the best policy yields a Q-function that is stable by the optimal Bellman operator (for the Q-function) $\\mathcal{B}(f(s,a)) = r(s,a) + \\mathbb{E}_{s'}[\\max_{a'}f(s',a')]$. The distance between a Q-function and its image by the optimal Bellman operator is thus a mesure of how \"good\" (ie how close to the optimal solution) our function is.\n",
    "\n",
    "This distance is then squared to ensure that the problem we are trying to solve is convex.\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        self.memory.append(m)\n",
    "        if len(self.memory)>self.max_memory:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def random_access(self):\n",
    "        index = random.randint(0, len(self.memory)-1)\n",
    "        return self.memory[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "    scores = []\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        win_count = 0\n",
    "        lose_count = 0\n",
    "        \n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            # win_count and lose_count counts the number of times we landed on good/bad cells\n",
    "            # To be able to compare exploration strategies to previous results\n",
    "            if reward > 0:\n",
    "                win_count += 0.5\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                if reward < -0.5: lose_count += 1\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "        scores.append(win_count-lose_count)\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "\n",
    "        input_ = s.reshape(1,5,5,self.n_state)\n",
    "        q_values = self.model.predict(input_)\n",
    "        return np.argmax(q_values)\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4)) # 4 stands for the number of actions?\n",
    "        next_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        actions = np.zeros((self.batch_size))\n",
    "        game_overs = np.zeros((self.batch_size))\n",
    "        rewards = np.zeros((self.batch_size))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            \n",
    "            s_, n_s_, a_, r_, game_over = self.memory.random_access()\n",
    "            input_states[i] = s_\n",
    "            next_states[i] = n_s_\n",
    "            actions[i] = a_\n",
    "            game_overs[i] = game_over_\n",
    "            rewards[i] = r_\n",
    "            \n",
    "        target_q[:] = self.model.predict(input_states)\n",
    "        next_state_qs = self.model.predict(next_states)\n",
    "        best_next_state_qs = np.amax(next_state_qs, axis=1)\n",
    "        actions = actions.astype(int)\n",
    "        for i in range(self.batch_size):\n",
    "            target_q[i, actions[i]] = rewards[i] + (1-game_overs[i])*best_next_state_qs[i]\n",
    "        \n",
    "            \n",
    "        \n",
    "        ######## FILL IN # Did not find anything to add here\n",
    "        \n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    # Takes as input only the state, and returns one output per action (to be consistent with the code given)\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Reshape((5*5*self.n_state,), input_shape=(5,5,self.n_state,)))\n",
    "        model.add(Dense(32, input_dim=5*5*self.n_state, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(4, activation='linear'))\n",
    "        \n",
    "        model.compile(adam(lr=lr, decay=1e-4), \"mse\") # momentum=0.0\n",
    "        self.model = model\n",
    "        print(model.summary())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 2,820\n",
      "Trainable params: 2,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 000/100 | Loss 0.0722 | Win/lose count 3.0/4.0 (-1.0)\n",
      "Epoch 001/100 | Loss 0.0711 | Win/lose count 2.0/4.0 (-2.0)\n",
      "Epoch 002/100 | Loss 0.0414 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 003/100 | Loss 0.0318 | Win/lose count 7.0/9.0 (-2.0)\n",
      "Epoch 004/100 | Loss 0.0444 | Win/lose count 2.0/3.0 (-1.0)\n",
      "Epoch 005/100 | Loss 0.0621 | Win/lose count 2.0/0 (2.0)\n",
      "Epoch 006/100 | Loss 0.1028 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 007/100 | Loss 0.1961 | Win/lose count 4.0/6.0 (-2.0)\n",
      "Epoch 008/100 | Loss 0.2599 | Win/lose count 4.0/5.0 (-1.0)\n",
      "Epoch 009/100 | Loss 0.4414 | Win/lose count 4.0/7.0 (-3.0)\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=0.0001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "scores = train(agent, env, epochs_train, prefix='fc_train')\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.title('Evolution of scores through the epochs')\n",
    "plt.show()\n",
    "#HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(display_videos('fc_train90.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        ###### FILL IN\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(8,3, input_shape = (5,5,self.n_state,), padding=\"same\"))\n",
    "        model.add(Conv2D(8,3, padding=\"same\"))\n",
    "        model.add(Reshape((5*5*8,), input_shape=(5,5,8,)))\n",
    "        model.add(Dense(32, input_dim=5*5*8, activation='relu'))\n",
    "        model.add(Dense(4, activation='linear'))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        print(model.summary())\n",
    "        \n",
    "        # Could not find better parameters with adam\n",
    "        model.compile(sgd(lr=lr, decay=1e-4), \"mse\") # momentum=0.0\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "scores = train(agent,env,epochs_train,prefix='cnn_train')\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.title('Evolution of scores through the epochs')\n",
    "plt.show()\n",
    "#HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(display_videos('cnn_train90.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 5, 5, 8)           152       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 5, 5, 8)           584       \n",
      "_________________________________________________________________\n",
      "reshape_17 (Reshape)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                6432      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,300\n",
      "Trainable params: 7,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_18 (Reshape)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 2,820\n",
      "Trainable params: 2,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test of the CNN\n",
      "Win/lose count 2.0/0. Average score (2.0)\n",
      "Win/lose count 1.5/0. Average score (1.75)\n",
      "Win/lose count 2.5/0. Average score (2.0)\n",
      "Win/lose count 0.5/0. Average score (1.625)\n",
      "Win/lose count 1.5/0. Average score (1.6)\n",
      "Win/lose count 4.5/1.0. Average score (1.9166666666666667)\n",
      "Win/lose count 3.5/2.0. Average score (1.8571428571428572)\n",
      "Win/lose count 1.0/0. Average score (1.75)\n",
      "Win/lose count 2.5/1.0. Average score (1.7222222222222223)\n",
      "Win/lose count 3.5/0. Average score (1.9)\n",
      "Win/lose count 4.5/1.0. Average score (2.0454545454545454)\n",
      "Win/lose count 1.0/0. Average score (1.9583333333333333)\n",
      "Win/lose count 0.5/0. Average score (1.8461538461538463)\n",
      "Win/lose count 3.0/0. Average score (1.9285714285714286)\n",
      "Win/lose count 4.5/0. Average score (2.1)\n",
      "Win/lose count 2.0/0. Average score (2.09375)\n",
      "Win/lose count 1.0/0. Average score (2.0294117647058822)\n",
      "Win/lose count 2.5/2.0. Average score (1.9444444444444444)\n",
      "Win/lose count 1.5/0. Average score (1.9210526315789473)\n",
      "Win/lose count 2.0/2.0. Average score (1.825)\n",
      "Final score: 1.825\n",
      "Test of the FC\n",
      "Win/lose count 2.5/4.0. Average score (-1.5)\n",
      "Win/lose count 5.5/3.0. Average score (0.5)\n",
      "Win/lose count 5.5/10.0. Average score (-1.1666666666666667)\n",
      "Win/lose count 4.5/8.0. Average score (-1.75)\n",
      "Win/lose count 3.5/2.0. Average score (-1.1)\n",
      "Win/lose count 3.5/8.0. Average score (-1.6666666666666667)\n",
      "Win/lose count 3.5/3.0. Average score (-1.3571428571428572)\n",
      "Win/lose count 6.5/6.0. Average score (-1.125)\n",
      "Win/lose count 2.5/1.0. Average score (-0.8333333333333334)\n",
      "Win/lose count 4.0/7.0. Average score (-1.05)\n",
      "Win/lose count 1.5/1.0. Average score (-0.9090909090909091)\n",
      "Win/lose count 3.5/7.0. Average score (-1.125)\n",
      "Win/lose count 6.5/6.0. Average score (-1.0)\n",
      "Win/lose count 3.5/1.0. Average score (-0.75)\n",
      "Win/lose count 4.0/2.0. Average score (-0.5666666666666667)\n",
      "Win/lose count 1.0/1.0. Average score (-0.53125)\n",
      "Win/lose count 3.5/4.0. Average score (-0.5294117647058824)\n",
      "Win/lose count 2.5/3.0. Average score (-0.5277777777777778)\n",
      "Win/lose count 3.5/1.0. Average score (-0.3684210526315789)\n",
      "Win/lose count 3.5/8.0. Average score (-0.575)\n",
      "Final score: -0.575\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.0001, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## use those samples of code:\\n#In train explore:\\nstate, reward, game_over = env.act(action, train=True)\\n\\n## In Environment exploring:\\n# You will have to change n_state to 3 because you will use one more layer!\\nreward = 0\\nif train:\\n    reward = -self.malus_position[self.x, self.y]\\nself.malus_position[self.x, self.y] = 0.1\\n\\nreward = reward + self.board[self.x, self.y]\\n# 3 \"feature\" states instead of 2\\nstate = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\\n                                self.board.reshape(self.grid_size, self.grid_size,1),\\n                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    # Decrease epsilon from 0.9 to 0.1 (min is reached at 2/3 of the training)\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "    scores = []\n",
    "    \n",
    "    start_epsilon = 0.5\n",
    "    end_epsilon = 0.1\n",
    "    stop = int(epoch*(2/3))\n",
    "    decrease = (start_epsilon-end_epsilon)/stop\n",
    "    \n",
    "    epsilon = start_epsilon\n",
    "    agent.set_epsilon(epsilon)\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "        \n",
    "        if e<stop:\n",
    "            epsilon -= decrease\n",
    "            agent.set_epsilon(epsilon)\n",
    "        \n",
    "        win = 0\n",
    "        lose = 0\n",
    "        win_count = 0\n",
    "        lose_count = 0\n",
    "        \n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win_count += 0.5\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                if reward < -0.5: lose_count += 1\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "        scores.append(win_count-lose_count)\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "    return scores\n",
    "        \n",
    "class EnvironmentExploring(Environment):\n",
    "\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        \n",
    "        super(EnvironmentExploring, self).__init__(grid_size, max_time, temperature)\n",
    "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        if train:\n",
    "            reward -= self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] = 0.1\n",
    "        self.board[self.x, self.y] = 0\n",
    "\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "    \n",
    "        # Do not forget to reset the position malus\n",
    "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        #print(self.board)\n",
    "        return state\n",
    "    \n",
    "'''## use those samples of code:\n",
    "#In train explore:\n",
    "state, reward, game_over = env.act(action, train=True)\n",
    "\n",
    "## In Environment exploring:\n",
    "# You will have to change n_state to 3 because you will use one more layer!\n",
    "reward = 0\n",
    "if train:\n",
    "    reward = -self.malus_position[self.x, self.y]\n",
    "self.malus_position[self.x, self.y] = 0.1\n",
    "\n",
    "reward = reward + self.board[self.x, self.y]\n",
    "# 3 \"feature\" states instead of 2\n",
    "state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 5, 5, 8)           224       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 5, 5, 8)           584       \n",
      "_________________________________________________________________\n",
      "reshape_19 (Reshape)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 32)                6432      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,372\n",
      "Trainable params: 7,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 000/100 | Loss 0.0976 | Win/lose count 3.0/27.600000000000147 (-24.600000000000147)\n",
      "Epoch 001/100 | Loss 2.0394 | Win/lose count 5.0/20.799999999999997 (-15.799999999999997)\n",
      "Epoch 002/100 | Loss 0.4177 | Win/lose count 5.5/21.800000000000043 (-16.300000000000043)\n",
      "Epoch 003/100 | Loss 0.5111 | Win/lose count 11.0/21.800000000000026 (-10.800000000000026)\n",
      "Epoch 004/100 | Loss 1.9155 | Win/lose count 10.5/24.200000000000077 (-13.700000000000077)\n",
      "Epoch 005/100 | Loss 1.9348 | Win/lose count 16.0/18.799999999999997 (-2.799999999999997)\n",
      "Epoch 006/100 | Loss 1.8912 | Win/lose count 13.0/22.200000000000067 (-9.200000000000067)\n",
      "Epoch 007/100 | Loss 1.6984 | Win/lose count 7.0/17.29999999999998 (-10.29999999999998)\n",
      "Epoch 008/100 | Loss 1.8136 | Win/lose count 5.5/18.800000000000004 (-13.300000000000004)\n",
      "Epoch 009/100 | Loss 1.8268 | Win/lose count 12.5/25.600000000000055 (-13.100000000000055)\n",
      "Epoch 010/100 | Loss 2.0102 | Win/lose count 13.5/24.300000000000054 (-10.800000000000054)\n",
      "Epoch 011/100 | Loss 1.8236 | Win/lose count 10.5/16.89999999999997 (-6.39999999999997)\n",
      "Epoch 012/100 | Loss 1.8239 | Win/lose count 14.0/17.999999999999993 (-3.999999999999993)\n",
      "Epoch 013/100 | Loss 1.8735 | Win/lose count 7.5/25.400000000000034 (-17.900000000000034)\n",
      "Epoch 014/100 | Loss 1.7247 | Win/lose count 21.5/19.80000000000002 (1.6999999999999815)\n",
      "Epoch 015/100 | Loss 1.8561 | Win/lose count 12.0/21.700000000000024 (-9.700000000000024)\n",
      "Epoch 016/100 | Loss 1.7750 | Win/lose count 11.5/22.40000000000005 (-10.900000000000048)\n",
      "Epoch 017/100 | Loss 1.7751 | Win/lose count 9.0/18.999999999999993 (-9.999999999999993)\n",
      "Epoch 018/100 | Loss 1.8107 | Win/lose count 22.5/21.600000000000048 (0.8999999999999524)\n",
      "Epoch 019/100 | Loss 1.7748 | Win/lose count 17.0/21.200000000000042 (-4.200000000000042)\n",
      "Epoch 020/100 | Loss 1.7117 | Win/lose count 12.5/19.899999999999984 (-7.399999999999984)\n",
      "Epoch 021/100 | Loss 1.6749 | Win/lose count 11.5/18.800000000000008 (-7.300000000000008)\n",
      "Epoch 022/100 | Loss 1.7836 | Win/lose count 16.5/18.899999999999984 (-2.3999999999999844)\n",
      "Epoch 023/100 | Loss 1.7521 | Win/lose count 21.0/16.79999999999998 (4.200000000000021)\n",
      "Epoch 024/100 | Loss 1.7354 | Win/lose count 11.5/21.90000000000006 (-10.400000000000059)\n",
      "Epoch 025/100 | Loss 1.6991 | Win/lose count 17.0/15.999999999999966 (1.0000000000000338)\n",
      "Epoch 026/100 | Loss 1.6912 | Win/lose count 12.5/18.3 (-5.800000000000001)\n",
      "Epoch 027/100 | Loss 1.7046 | Win/lose count 9.0/19.000000000000007 (-10.000000000000007)\n",
      "Epoch 028/100 | Loss 1.7932 | Win/lose count 23.0/17.099999999999994 (5.900000000000006)\n",
      "Epoch 029/100 | Loss 1.6980 | Win/lose count 19.0/17.599999999999994 (1.4000000000000057)\n",
      "Epoch 030/100 | Loss 1.7051 | Win/lose count 7.0/20.50000000000003 (-13.500000000000028)\n",
      "Epoch 031/100 | Loss 1.6529 | Win/lose count 17.5/16.199999999999974 (1.3000000000000256)\n",
      "Epoch 032/100 | Loss 1.5599 | Win/lose count 11.5/19.90000000000003 (-8.40000000000003)\n",
      "Epoch 033/100 | Loss 1.6519 | Win/lose count 18.5/19.400000000000006 (-0.9000000000000057)\n",
      "Epoch 034/100 | Loss 1.4904 | Win/lose count 23.0/17.299999999999976 (5.700000000000024)\n",
      "Epoch 035/100 | Loss 1.6401 | Win/lose count 18.0/18.2 (-0.1999999999999993)\n",
      "Epoch 036/100 | Loss 1.6514 | Win/lose count 17.0/17.599999999999994 (-0.5999999999999943)\n",
      "Epoch 037/100 | Loss 1.6611 | Win/lose count 15.5/18.29999999999999 (-2.79999999999999)\n",
      "Epoch 038/100 | Loss 1.6185 | Win/lose count 21.0/17.799999999999994 (3.2000000000000064)\n",
      "Epoch 039/100 | Loss 1.5599 | Win/lose count 11.0/19.200000000000014 (-8.200000000000014)\n",
      "Epoch 040/100 | Loss 1.5718 | Win/lose count 18.5/19.20000000000001 (-0.70000000000001)\n",
      "Epoch 041/100 | Loss 1.5865 | Win/lose count 20.0/19.399999999999995 (0.600000000000005)\n",
      "Epoch 042/100 | Loss 1.7416 | Win/lose count 18.5/15.09999999999998 (3.40000000000002)\n",
      "Epoch 043/100 | Loss 1.5673 | Win/lose count 19.0/16.699999999999985 (2.300000000000015)\n",
      "Epoch 044/100 | Loss 1.5919 | Win/lose count 21.0/17.90000000000001 (3.0999999999999908)\n",
      "Epoch 045/100 | Loss 1.6236 | Win/lose count 19.5/15.299999999999976 (4.200000000000024)\n",
      "Epoch 046/100 | Loss 1.5925 | Win/lose count 16.0/15.699999999999966 (0.30000000000003446)\n",
      "Epoch 047/100 | Loss 1.4942 | Win/lose count 21.0/16.599999999999984 (4.400000000000016)\n",
      "Epoch 048/100 | Loss 1.5513 | Win/lose count 25.0/16.69999999999998 (8.300000000000018)\n",
      "Epoch 049/100 | Loss 1.5699 | Win/lose count 23.5/12.599999999999978 (10.900000000000022)\n",
      "Epoch 050/100 | Loss 1.5738 | Win/lose count 20.0/17.299999999999972 (2.7000000000000277)\n",
      "Epoch 051/100 | Loss 1.6719 | Win/lose count 15.5/19.69999999999999 (-4.199999999999989)\n",
      "Epoch 052/100 | Loss 1.5103 | Win/lose count 21.0/18.300000000000015 (2.699999999999985)\n",
      "Epoch 053/100 | Loss 1.4289 | Win/lose count 21.5/16.699999999999978 (4.800000000000022)\n",
      "Epoch 054/100 | Loss 1.5105 | Win/lose count 15.5/15.799999999999974 (-0.29999999999997407)\n",
      "Epoch 055/100 | Loss 1.4987 | Win/lose count 22.5/13.69999999999998 (8.80000000000002)\n",
      "Epoch 056/100 | Loss 1.4108 | Win/lose count 24.0/14.899999999999977 (9.100000000000023)\n",
      "Epoch 057/100 | Loss 1.5967 | Win/lose count 19.5/19.200000000000006 (0.2999999999999936)\n",
      "Epoch 058/100 | Loss 1.4885 | Win/lose count 21.5/12.999999999999973 (8.500000000000027)\n",
      "Epoch 059/100 | Loss 1.5044 | Win/lose count 22.0/15.599999999999975 (6.400000000000025)\n",
      "Epoch 060/100 | Loss 1.3917 | Win/lose count 17.0/15.499999999999963 (1.5000000000000373)\n",
      "Epoch 061/100 | Loss 1.4656 | Win/lose count 20.0/15.599999999999971 (4.400000000000029)\n",
      "Epoch 062/100 | Loss 1.4431 | Win/lose count 12.0/15.499999999999964 (-3.4999999999999645)\n",
      "Epoch 063/100 | Loss 1.4585 | Win/lose count 21.0/10.799999999999983 (10.200000000000017)\n",
      "Epoch 064/100 | Loss 1.5728 | Win/lose count 33.0/9.199999999999983 (23.80000000000002)\n",
      "Epoch 065/100 | Loss 1.4659 | Win/lose count 24.5/14.099999999999977 (10.400000000000023)\n",
      "Epoch 066/100 | Loss 1.4829 | Win/lose count 22.0/12.499999999999975 (9.500000000000025)\n",
      "Epoch 067/100 | Loss 1.6082 | Win/lose count 23.5/12.09999999999998 (11.40000000000002)\n",
      "Epoch 068/100 | Loss 1.4510 | Win/lose count 26.0/13.19999999999998 (12.80000000000002)\n",
      "Epoch 069/100 | Loss 1.5843 | Win/lose count 22.0/15.199999999999969 (6.800000000000031)\n",
      "Epoch 070/100 | Loss 1.4175 | Win/lose count 16.5/13.09999999999997 (3.4000000000000306)\n",
      "Epoch 071/100 | Loss 1.6501 | Win/lose count 19.5/16.79999999999998 (2.7000000000000206)\n",
      "Epoch 072/100 | Loss 1.5758 | Win/lose count 29.0/11.299999999999983 (17.700000000000017)\n",
      "Epoch 073/100 | Loss 1.5936 | Win/lose count 16.5/17.89999999999999 (-1.3999999999999915)\n",
      "Epoch 074/100 | Loss 1.5466 | Win/lose count 16.5/14.899999999999974 (1.6000000000000263)\n",
      "Epoch 075/100 | Loss 1.5464 | Win/lose count 21.0/14.99999999999997 (6.00000000000003)\n",
      "Epoch 076/100 | Loss 1.5547 | Win/lose count 22.0/16.799999999999983 (5.200000000000017)\n",
      "Epoch 077/100 | Loss 1.5231 | Win/lose count 20.0/12.399999999999979 (7.600000000000021)\n",
      "Epoch 078/100 | Loss 1.3774 | Win/lose count 21.0/13.599999999999975 (7.400000000000025)\n",
      "Epoch 079/100 | Loss 1.4626 | Win/lose count 26.0/10.999999999999984 (15.000000000000016)\n",
      "Epoch 080/100 | Loss 1.2938 | Win/lose count 12.5/17.899999999999977 (-5.399999999999977)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 081/100 | Loss 1.3457 | Win/lose count 19.0/17.299999999999997 (1.7000000000000028)\n",
      "Epoch 082/100 | Loss 1.3656 | Win/lose count 20.5/15.199999999999976 (5.300000000000024)\n",
      "Epoch 083/100 | Loss 1.4453 | Win/lose count 21.0/13.499999999999972 (7.500000000000028)\n",
      "Epoch 084/100 | Loss 1.5232 | Win/lose count 23.0/13.799999999999976 (9.200000000000024)\n",
      "Epoch 085/100 | Loss 1.2947 | Win/lose count 12.5/16.899999999999974 (-4.399999999999974)\n",
      "Epoch 086/100 | Loss 1.4146 | Win/lose count 18.0/15.299999999999965 (2.700000000000035)\n",
      "Epoch 087/100 | Loss 1.4074 | Win/lose count 18.5/13.699999999999974 (4.800000000000026)\n",
      "Epoch 088/100 | Loss 1.2969 | Win/lose count 15.5/14.899999999999965 (0.6000000000000352)\n",
      "Epoch 089/100 | Loss 1.0332 | Win/lose count 22.5/13.39999999999998 (9.10000000000002)\n",
      "Epoch 090/100 | Loss 1.2704 | Win/lose count 16.5/14.99999999999997 (1.5000000000000302)\n",
      "Epoch 091/100 | Loss 1.1564 | Win/lose count 25.0/14.099999999999977 (10.900000000000023)\n",
      "Epoch 092/100 | Loss 1.1899 | Win/lose count 21.5/12.09999999999998 (9.40000000000002)\n",
      "Epoch 093/100 | Loss 1.4071 | Win/lose count 25.5/11.99999999999998 (13.50000000000002)\n",
      "Epoch 094/100 | Loss 1.3285 | Win/lose count 18.0/15.299999999999974 (2.700000000000026)\n",
      "Epoch 095/100 | Loss 1.3685 | Win/lose count 15.0/16.49999999999997 (-1.4999999999999716)\n",
      "Epoch 096/100 | Loss 1.5096 | Win/lose count 17.5/15.099999999999966 (2.400000000000034)\n",
      "Epoch 097/100 | Loss 1.3690 | Win/lose count 18.0/11.19999999999998 (6.80000000000002)\n",
      "Epoch 098/100 | Loss 1.3871 | Win/lose count 22.0/15.399999999999972 (6.600000000000028)\n",
      "Epoch 099/100 | Loss 1.2831 | Win/lose count 20.0/15.299999999999972 (4.700000000000028)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
    "scores = train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.title('Evolution of the score through the epochs')\n",
    "plt.show()\n",
    "\n",
    "#HTML(display_videos('cnn_train_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_train_explore90.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 9.5/17.499999999999986. Average score (-7.999999999999986)\n",
      "Win/lose count 5.5/20.100000000000026. Average score (-11.300000000000006)\n",
      "Win/lose count 17.5/15.899999999999977. Average score (-6.9999999999999964)\n",
      "Win/lose count 12.0/17.099999999999984. Average score (-6.524999999999993)\n",
      "Win/lose count 20.0/17.39999999999999. Average score (-4.699999999999993)\n",
      "Win/lose count 10.5/18.8. Average score (-5.2999999999999945)\n",
      "Win/lose count 11.0/16.399999999999967. Average score (-5.314285714285704)\n",
      "Win/lose count 7.0/18.39999999999999. Average score (-6.07499999999999)\n",
      "Win/lose count 8.0/19.0. Average score (-6.622222222222214)\n",
      "Win/lose count 23.5/13.299999999999976. Average score (-4.93999999999999)\n",
      "Win/lose count 20.0/13.199999999999969. Average score (-3.8727272727272606)\n",
      "Win/lose count 19.0/15.599999999999964. Average score (-3.266666666666653)\n",
      "Win/lose count 22.5/14.299999999999969. Average score (-2.3846153846153695)\n",
      "Win/lose count 20.5/15.499999999999975. Average score (-1.8571428571428412)\n",
      "Win/lose count 11.5/18.199999999999996. Average score (-2.179999999999985)\n",
      "Win/lose count 6.0/20.300000000000004. Average score (-2.9374999999999862)\n",
      "Win/lose count 19.0/16.79999999999998. Average score (-2.6352941176470446)\n",
      "Win/lose count 12.0/16.09999999999996. Average score (-2.716666666666651)\n",
      "Win/lose count 23.0/12.899999999999977. Average score (-2.0421052631578784)\n",
      "Win/lose count 16.0/16.29999999999997. Average score (-1.954999999999983)\n",
      "Final score: -1.954999999999983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
